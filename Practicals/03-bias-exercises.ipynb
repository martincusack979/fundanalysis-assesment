{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4e20a6",
   "metadata": {},
   "source": [
    "## Bias\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676e090",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e92e68",
   "metadata": {},
   "source": [
    "#### *Give three real-world examples of cognitive bias*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7cb17",
   "metadata": {},
   "source": [
    "* Confirmation bias: selectively absorbing only information which reinforces your existing beliefs. An example of this could be if you leaned towards a conservative political outlook, but only consumed news/information from Fox News etc., you will inevitably end up with a distorted picture of the social/political landscape which validates your existing prejudices.  Daniel Kahneman wrote about this phenomenon in his book \"Thinking, Fast and Slow\", in a chapter entitled \"A Machine for Jumping to Conclusions\" : \"Contrary to the rules of philosophers of science, who advise testing hypotheses by trying to refute them, people (and scientists, quite often) seek data that are likely to be compatible with the beliefs they currently hold\".\n",
    "\n",
    "\n",
    "* Hyperbolic discounting: \"our inclination to choose immediate rewards over rewards that come later in the future, even when these immediate rewards are smaller.\" An example of this: we are all increasingly aware of the environmental cost of air travel, yet we continue to fly because it suits us in the short-term and we do not have an immediate sense of the damage which harmful emissions are causing to the environment in the long-term.\n",
    "\n",
    "\n",
    "* Bandwagon effect: \"Uptick of beliefs and ideas increases the more that they have already been adopted by others.\"  An example of this would be the recent surge in investments in cryptocurrency and NFTs. Despite the relative lack of knowledge of such a new and untested phenomenon and the extremely high risk involved, many jumped at the chance to invest in crypto and NFT purely because other (often high-profile) people had shown an interest in same.\n",
    "\n",
    "\n",
    "#### *References:* \n",
    "\n",
    "https://positivepsychology.com/cognitive-biases/\n",
    "\n",
    "Kahneman, Daniel. *Thinking Fast and Slow* Penguin Books, 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17ac4b",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a sample of 1000 values from a normal distribution.\n",
    "x = np.random.normal(10.0, 1.0, 1000)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect the mean of the sample to be close to the mean of the population.\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run a simulation of taking 1000 samples of size 1000.\n",
    "samples = np.random.normal(10.0, 1.0, (1000, 1000))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092362c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of the first sample.\n",
    "samples[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b58dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of all samples.\n",
    "sample_means = samples.mean(axis=1)\n",
    "sample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f199a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sample_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70326484",
   "metadata": {},
   "source": [
    "### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of numbers - four small and one big.\n",
    "numbers1 = np.array([1, 1, 1, 1, 10])\n",
    "\n",
    "# Their mean.\n",
    "np.mean(numbers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of numbers - all close to each other.\n",
    "numbers2 = np.array([2, 2, 3, 3, 4])\n",
    "\n",
    "# Their mean.\n",
    "np.mean(numbers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347d125",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the mean.\n",
    "x_mean = x.mean()\n",
    "\n",
    "# Subtract the mean from each of the values.\n",
    "zeroed = x - x_mean\n",
    "\n",
    "# Have a look at the zeroed values.\n",
    "zeroed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the mean of zeroed is?\n",
    "zeroed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot.\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the zeroed array, each value spaced out evenly along the x axis.\n",
    "# Note the x axis is just the position of the value in the zeroed array.\n",
    "ax.plot(range(len(zeroed)), zeroed, 'k.')\n",
    "\n",
    "# Plot the y=0 line.\n",
    "ax.axhline(y=0.0, color='grey', linestyle='-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d4141",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Absolute values.\n",
    "np.abs(zeroed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94012c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average absolute value.\n",
    "np.mean(np.abs(zeroed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fccff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square the values.\n",
    "np.square(zeroed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270766d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a plot.\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the squared zeroed array, each value spaced out evenly along the x axis.\n",
    "# Note the x axis is just the position of the value in the zeroed array.\n",
    "ax.plot(range(len(zeroed)), np.square(zeroed), color='green', marker='.', linestyle='none')\n",
    "\n",
    "# Plot the zeroed array, each value spaced out evenly along the x axis.\n",
    "# Note the x axis is just the position of the value in the zeroed array.\n",
    "ax.plot(range(len(zeroed)), zeroed, 'k.')\n",
    "\n",
    "# Plot the y=0 line.\n",
    "ax.axhline(y=0.0, color='grey', linestyle='-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average squared result.\n",
    "np.mean(np.square(zeroed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the square root of the average squared result.\n",
    "np.sqrt(np.mean(np.square(zeroed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full calculation using the original array.\n",
    "np.sqrt(np.mean(np.square(x - np.mean(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the function is built into numpy.\n",
    "x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c3c34",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a560ea",
   "metadata": {},
   "source": [
    "#### *Calculate the standard deviations of the following two lists of numbers from earlier in the lecture:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numbers (4 small, 1 large)\n",
    "numbers1 = np.array([1, 1, 1, 1, 10])\n",
    "numbers1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfcad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numbers close together\n",
    "numbers2 = np.array([2, 2, 3, 3, 4])\n",
    "numbers2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed56d8",
   "metadata": {},
   "source": [
    "The above results make logical sense because the spread in the first list of numbers spans from 1 to 10, so is much wider than the second list of numbers, which are grouped tightly together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4c461",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82977ec2",
   "metadata": {},
   "source": [
    "#### *Show that the difference between the standard deviation calculations is greatest for small sample sizes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate std for small sample size\n",
    "sample_small = np.random.normal(0.0, 2.0, (10000, 5))\n",
    "sample_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b12c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviation without correction.\n",
    "stdevs_small = sample_small.std(axis=1)\n",
    "stdevs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99687d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create histogram to verify if estimate is too small.\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot histogram.\n",
    "plt.hist(stdevs_small, bins=10)\n",
    "\n",
    "# Draw a vertical line where the actual standard deviation is.\n",
    "plt.axvline(x=2.0, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccd292",
   "metadata": {},
   "source": [
    "As we can see from the histogram of the small sample size above, the estimate is clearly off as the bell curve is not centered on the std of 2.\n",
    "Next I will perform the same calculations on a large sample size for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca33ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate std for large sample size\n",
    "sample_large = np.random.normal(0.0, 2.0, (100, 10000))\n",
    "sample_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviation without correction.\n",
    "stdevs_large = sample_large.std(axis=1)\n",
    "stdevs_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram to check accuracy of estimate\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot histogram.\n",
    "plt.hist(stdevs_large, bins=10)\n",
    "\n",
    "# Draw a vertical line where the actual standard deviation is.\n",
    "plt.axvline(x=2.0, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d03f37",
   "metadata": {},
   "source": [
    "As we can see from the histogram of the much larger sample size above, the estimate is much more accurate as the bell curve is almost centered on the std of 2.\n",
    "\n",
    "As the website statisticshowto.com states: \"Warne (2017) advocates using Bessel’s correction only if you have a sufficiently large sample and if you are actually trying to approximate the population mean. If you are just interested in finding the sample mean, and don’t want to extrapolate your findings to the population, just omit the correction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2dd5b6",
   "metadata": {},
   "source": [
    "#### *References*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80f439",
   "metadata": {},
   "source": [
    "https://www.statisticshowto.com/bessels-correction/\n",
    "\n",
    "Warne, T. (2017). Statistics for the Social Sciences: A General Linear Model Approach. Cambridge University press.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c6da2",
   "metadata": {},
   "source": [
    "## End\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb185a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
